{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNP+3pyoBVcSn2ZLwZ6raqb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elf222/elf222/blob/main/Hackathons/Hackathon26_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting Google Drive"
      ],
      "metadata": {
        "id": "MwdszY8c2biM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaJSvABM2cH9",
        "outputId": "1f03d94a-333f-496c-e84d-5db6d3b0f64a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "working_directory = \"/content/drive/MyDrive/ForCollab/Hackathon/\""
      ],
      "metadata": {
        "id": "z3ZydjPC2lJ8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up data"
      ],
      "metadata": {
        "id": "PAppGer7FROw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling numerical data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(working_directory+\"train_data.csv\")\n",
        "\n",
        "# Define the range limits\n",
        "price_min_log, price_max_log = 9, 17\n",
        "area_min_log, area_max_log = 6, 10\n",
        "room_min_log, room_max_log = 0, 3\n",
        "\n",
        "# Apply natural logarithm transformation\n",
        "data['Area'] = np.log(data['Area'])\n",
        "data['Price'] = np.log(data['Price'])\n",
        "data['Bedrooms'] = np.log(data['Bedrooms'])\n",
        "data['Bathrooms'] = np.log(data['Bathrooms'])\n",
        "\n",
        "# Scale features to [0, 1]\n",
        "data['Area'] = (data['Area'] - area_min_log) / (area_max_log - area_min_log)\n",
        "data['Price'] = (data['Price'] - price_min_log) / (price_max_log - price_min_log)\n",
        "data['Bedrooms'] = (data['Bedrooms'] - room_min_log) / (room_max_log - room_min_log)\n",
        "data['Bathrooms'] = (data['Bathrooms'] - room_min_log) / (room_max_log - room_min_log)\n",
        "\n",
        "# Save the transformed data\n",
        "data.to_csv(working_directory+\"train_data_scaled.csv\", index=False)\n",
        "print(\"Data preprocessing complete. Transformed dataset saved as 'train_data_scaled.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IpWkClaFUUP",
        "outputId": "9415d4d4-25e2-4fa9-e344-049ad2f2fbb7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessing complete. Transformed dataset saved as 'train_data_scaled.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(working_directory+'train_data_scaled.csv')\n",
        "\n",
        "# Check that the required columns are present\n",
        "if 'Area' not in data.columns or 'Price' not in data.columns:\n",
        "    raise ValueError(\"Dataset must contain 'Area' and 'Price' columns.\")\n",
        "\n",
        "# Define the features and target variable\n",
        "X = data[['Area']]\n",
        "y = data['Price']\n",
        "\n",
        "# Fit a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict prices using the line of best fit\n",
        "data['predicted_price'] = model.predict(X)\n",
        "\n",
        "# Calculate the absolute distance from the line of best fit\n",
        "data['distance_from_fit'] = np.abs(data['Price'] - data['predicted_price'])\n",
        "\n",
        "# Determine the 98th percentile of the distance to exclude the top 2%\n",
        "threshold = data['distance_from_fit'].quantile(0.98)\n",
        "\n",
        "# Filter out the top 2% of outliers\n",
        "initial_count = len(data)\n",
        "cleaned_data = data[data['distance_from_fit'] <= threshold].drop(columns=['predicted_price', 'distance_from_fit'])\n",
        "final_count = len(cleaned_data)\n",
        "deleted_count = initial_count - final_count\n",
        "\n",
        "# Display progress\n",
        "for _ in tqdm(range(100), desc=\"Processing Data\"):\n",
        "    pass\n",
        "\n",
        "# Print the number of entries deleted\n",
        "print(f\"Entries processed: {initial_count}\")\n",
        "print(f\"Entries deleted: {deleted_count}\")\n",
        "\n",
        "# Save the cleaned dataset (optional)\n",
        "cleaned_data.to_csv(working_directory+'train_data_scaled_cleaned.csv', index=False)\n",
        "\n",
        "# Display the cleaned data\n",
        "cleaned_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "Um6rwFOskygM",
        "outputId": "a6295a83-f0ce-4b12-d36c-045c18d13429"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing Data: 100%|██████████| 100/100 [00:00<00:00, 427118.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entries processed: 428\n",
            "Entries deleted: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ID  Bedrooms  Bathrooms      Area  ZipCode     Price\n",
              "0  285  0.536479   0.536479  0.561740    92880  0.535964\n",
              "1  348  0.231049   0.231049  0.318100    92276  0.321399\n",
              "2  441  0.462098   0.366204  0.348316    93510  0.545957\n",
              "4  150  0.462098   0.501359  0.575876    92677  0.675064\n",
              "5  193  0.366204   0.231049  0.326633    94501  0.595396"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e62c82d-cfdd-4080-a308-b260a499bff4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Bedrooms</th>\n",
              "      <th>Bathrooms</th>\n",
              "      <th>Area</th>\n",
              "      <th>ZipCode</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>285</td>\n",
              "      <td>0.536479</td>\n",
              "      <td>0.536479</td>\n",
              "      <td>0.561740</td>\n",
              "      <td>92880</td>\n",
              "      <td>0.535964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>348</td>\n",
              "      <td>0.231049</td>\n",
              "      <td>0.231049</td>\n",
              "      <td>0.318100</td>\n",
              "      <td>92276</td>\n",
              "      <td>0.321399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>441</td>\n",
              "      <td>0.462098</td>\n",
              "      <td>0.366204</td>\n",
              "      <td>0.348316</td>\n",
              "      <td>93510</td>\n",
              "      <td>0.545957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>150</td>\n",
              "      <td>0.462098</td>\n",
              "      <td>0.501359</td>\n",
              "      <td>0.575876</td>\n",
              "      <td>92677</td>\n",
              "      <td>0.675064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>193</td>\n",
              "      <td>0.366204</td>\n",
              "      <td>0.231049</td>\n",
              "      <td>0.326633</td>\n",
              "      <td>94501</td>\n",
              "      <td>0.595396</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e62c82d-cfdd-4080-a308-b260a499bff4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e62c82d-cfdd-4080-a308-b260a499bff4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e62c82d-cfdd-4080-a308-b260a499bff4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dc5d32a6-5570-4583-8e76-a4feba395623\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc5d32a6-5570-4583-8e76-a4feba395623')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dc5d32a6-5570-4583-8e76-a4feba395623 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "cleaned_data",
              "summary": "{\n  \"name\": \"cleaned_data\",\n  \"rows\": 419,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 149,\n        \"min\": 2,\n        \"max\": 534,\n        \"num_unique_values\": 419,\n        \"samples\": [\n          295,\n          525,\n          124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11391228818199828,\n        \"min\": 0.0,\n        \"max\": 0.7675283643313486,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.6931471805599453,\n          0.2310490601866484,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bathrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11711149586498992,\n        \"min\": 0.0,\n        \"max\": 0.6486367163517711,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.5682493640794751,\n          0.6486367163517711,\n          0.5364793041447001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11671237949229021,\n        \"min\": 0.1381269717586475,\n        \"max\": 0.7348624655410596,\n        \"num_unique_values\": 348,\n        \"samples\": [\n          0.4500407675982401,\n          0.5065425487366064,\n          0.4679231660809113\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ZipCode\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6392,\n        \"min\": 36372,\n        \"max\": 98021,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          81418,\n          93720,\n          60002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10619402099808735,\n        \"min\": 0.2083283881145134,\n        \"max\": 0.7752256148855206,\n        \"num_unique_values\": 315,\n        \"samples\": [\n          0.5537310096440362,\n          0.4154819601483197,\n          0.6004297470912505\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling images\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "LCueDSclpQf8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "image_scaling_to = image_size//2"
      ],
      "metadata": {
        "id": "FddWLEAfuje2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(working_directory+\"train_data_scaled_cleaned.csv\")\n",
        "\n",
        "# Define directories\n",
        "image_dir = working_directory+\"images_train\"\n",
        "output_dir = working_directory+\"images_composition\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# List of rooms and positions in the composite image\n",
        "rooms = [\"kitchen\", \"bedroom\", \"bathroom\", \"frontal\"]\n",
        "positions = {\"kitchen\": (0, 0), \"bedroom\": (0, image_scaling_to), \"bathroom\": (image_scaling_to, 0), \"frontal\": (image_scaling_to, image_scaling_to)}\n",
        "\n",
        "progress_bar = tqdm(total=428, desc=\"Progress\", unit=\"step\")\n",
        "\n",
        "# Process images for each ID\n",
        "for property_id in data[\"ID\"]:\n",
        "    progress_bar.update(1)\n",
        "    # Create a blank composite image\n",
        "    composite_image = Image.new('RGB', (image_size, image_size))\n",
        "\n",
        "    # Load, resize, and place each room image in the composite\n",
        "    for room in rooms:\n",
        "        img_path = os.path.join(image_dir, f\"{property_id}_{room}.jpg\")\n",
        "        if os.path.exists(img_path):\n",
        "            img = Image.open(img_path)\n",
        "            img = img.resize((image_scaling_to, image_scaling_to), Image.LANCZOS)  # Resize to 32x32\n",
        "            composite_image.paste(img, positions[room])  # Paste at the designated position\n",
        "        else:\n",
        "            print(f\"Warning: {img_path} not found.\")\n",
        "\n",
        "    # Save the composite image\n",
        "    composite_image.save(os.path.join(output_dir, f\"{property_id}_composition.jpg\"))\n",
        "\n",
        "print(\"\\nImage formatting complete. Composite images saved in 'images_composite' directory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8IUA1nAJZaGq",
        "outputId": "c6ee301f-ae5a-4d0f-d3e1-4986c42fb043"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████| 428/428 [07:47<00:00,  1.07s/step]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image formatting complete. Composite images saved in 'images_composite' directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the model"
      ],
      "metadata": {
        "id": "9Nn1Q2sDwcN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the Google Drive destination folder\n",
        "destination_folder = working_directory+\"models/\"  # Customize this path if needed\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "class SaveEveryNEpochs(Callback):\n",
        "    def __init__(self, save_model_path, save_every=5):\n",
        "        super(SaveEveryNEpochs, self).__init__()\n",
        "        self.save_model_path = save_model_path\n",
        "        self.save_every = save_every\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.save_every == 0:  # Save every 'save_every' epochs\n",
        "            model_save_path = os.path.join(self.save_model_path, f'best_model2_epoch_{epoch + 1}.keras')\n",
        "            self.model.save(model_save_path)\n",
        "            print(f\"Model saved to {model_save_path} after epoch {epoch + 1}\")\n",
        "\n",
        "save_every_n_epochs = SaveEveryNEpochs(destination_folder, save_every=10)"
      ],
      "metadata": {
        "id": "Rn6_En1aEh0W"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "AQCoWPSLxC1D"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = image_size"
      ],
      "metadata": {
        "id": "ve8AS5-BUZDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load structured data\n",
        "data = pd.read_csv(working_directory+\"train_data_scaled_cleaned.csv\")\n",
        "\n",
        "# Separate features and target variable\n",
        "X_structured = data[['Bedrooms', 'Bathrooms', 'Area', 'ZipCode']].values\n",
        "y = data['Price'].values\n",
        "\n",
        "# Standardize the structured features\n",
        "scaler = StandardScaler()\n",
        "X_structured = scaler.fit_transform(X_structured)\n",
        "\n",
        "# Load images corresponding to each ID\n",
        "image_data = []\n",
        "image_ids = data['ID'].tolist()\n",
        "for img_id in image_ids:\n",
        "    img_path = f\"{working_directory}images_composition/{img_id}_composition.jpg\"  # adjust extension if needed\n",
        "    img = load_img(img_path, target_size=(image_size, image_size))\n",
        "    img_array = img_to_array(img)\n",
        "    image_data.append(img_array)\n",
        "X_images = np.array(image_data) / 255.0  # Normalize pixel values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train_img, X_test_img, X_train_struct, X_test_struct, y_train, y_test = train_test_split(\n",
        "    X_images, X_structured, y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# Load the VGG16 model without the top layers and freeze its layers\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "for layer in vgg_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Define input layers\n",
        "image_input = Input(shape=(image_size, image_size, 3))\n",
        "structured_input = Input(shape=(X_structured.shape[1],))\n",
        "\n",
        "# VGG16-based CNN model for image processing\n",
        "x = vgg_base(image_input)\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Fully connected layers for structured data\n",
        "y = Dense(64, activation='relu')(structured_input)\n",
        "y = Dense(32, activation='relu')(y)\n",
        "\n",
        "# Concatenate the outputs of CNN and structured data layers\n",
        "combined = Concatenate()([x, y])\n",
        "z = Dense(128, activation='relu')(combined)\n",
        "z = Dense(64, activation='relu')(z)\n",
        "output = Dense(1)(z)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=[image_input, structured_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.005), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Display training progress\n",
        "checkpoint = ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\")\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)\n",
        "\n",
        "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=5e-6)\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_img, X_train_struct],\n",
        "    y_train,\n",
        "    validation_data=([X_test_img, X_test_struct], y_test),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[checkpoint, early_stopping, save_every_n_epochs, reduce_lr_on_plateau],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "bOQi7pvZw-Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up test data:"
      ],
      "metadata": {
        "id": "Sv-XHtTeRJMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling numerical data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(working_directory+\"test_data_no_target.csv\")\n",
        "\n",
        "# Define the range limits\n",
        "price_min_log, price_max_log = 9, 17\n",
        "area_min_log, area_max_log = 6, 10\n",
        "room_min_log, room_max_log = 0, 3\n",
        "\n",
        "# Apply natural logarithm transformation\n",
        "data['Area'] = np.log(data['Area'])\n",
        "data['Bedrooms'] = np.log(data['Bedrooms'])\n",
        "data['Bathrooms'] = np.log(data['Bathrooms'])\n",
        "\n",
        "# Scale features to [0, 1]\n",
        "data['Area'] = (data['Area'] - area_min_log) / (area_max_log - area_min_log)\n",
        "data['Bedrooms'] = (data['Bedrooms'] - room_min_log) / (room_max_log - room_min_log)\n",
        "data['Bathrooms'] = (data['Bathrooms'] - room_min_log) / (room_max_log - room_min_log)\n",
        "\n",
        "# Save the transformed data\n",
        "data.to_csv(working_directory+\"test_data_scaled.csv\", index=False)\n",
        "print(\"Data preprocessing complete. Transformed dataset saved as 'test_data_scaled.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wAP_I-GRIhF",
        "outputId": "b9a56afc-279e-494e-ca8c-765f85a419a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessing complete. Transformed dataset saved as 'test_data_scaled.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling images\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "RvcdIi9RUZzw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "image_scaling_to = image_size//2"
      ],
      "metadata": {
        "id": "vK4ejjJ_Uk5V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(working_directory+\"test_data_scaled.csv\")\n",
        "\n",
        "# Define directories\n",
        "image_dir = working_directory+\"images_test\"\n",
        "output_dir = working_directory+\"images_composition_test\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# List of rooms and positions in the composite image\n",
        "rooms = [\"kitchen\", \"bedroom\", \"bathroom\", \"frontal\"]\n",
        "positions = {\"kitchen\": (0, 0), \"bedroom\": (0, image_scaling_to), \"bathroom\": (image_scaling_to, 0), \"frontal\": (image_scaling_to, image_scaling_to)}\n",
        "\n",
        "progress_bar = tqdm(total=107, desc=\"Progress\", unit=\"step\")\n",
        "\n",
        "# Process images for each ID\n",
        "for property_id in data[\"ID\"]:\n",
        "    progress_bar.update(1)\n",
        "    # Create a blank composite image\n",
        "    composite_image = Image.new('RGB', (image_size, image_size))\n",
        "\n",
        "    # Load, resize, and place each room image in the composite\n",
        "    for room in rooms:\n",
        "        img_path = os.path.join(image_dir, f\"{property_id}_{room}.jpg\")\n",
        "        if os.path.exists(img_path):\n",
        "            img = Image.open(img_path)\n",
        "            img = img.resize((image_scaling_to, image_scaling_to), Image.LANCZOS)  # Resize to 32x32\n",
        "            composite_image.paste(img, positions[room])  # Paste at the designated position\n",
        "        else:\n",
        "            print(f\"Warning: {img_path} not found.\")\n",
        "\n",
        "    # Save the composite image\n",
        "    composite_image.save(os.path.join(output_dir, f\"{property_id}_composition.jpg\"))\n",
        "\n",
        "print(\"\\nImage formatting complete. Composite images saved in 'images_composite' directory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_AqZM3pUn0r",
        "outputId": "a22a425d-43cb-489b-95dd-f223736a232b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████| 107/107 [01:53<00:00,  1.02s/step]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image formatting complete. Composite images saved in 'images_composite' directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting:"
      ],
      "metadata": {
        "id": "iwlrGuleF0WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "GpSJCLO-FzmO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model = load_model(\"/content/WithGPUForNowTheBest_loss-0.007,mae-0.0672.keras\")\n",
        "\n",
        "# Load test data\n",
        "test_data = pd.read_csv(working_directory+\"test_data_scaled.csv\")\n",
        "\n",
        "# Separate the structured data (without the Price column)\n",
        "X_test_structured = test_data[['Bedrooms', 'Bathrooms', 'Area', 'ZipCode']].values\n",
        "\n",
        "# Standardize the structured features using the same scaler used in training\n",
        "scaler = StandardScaler()\n",
        "X_test_structured = scaler.fit_transform(X_test_structured)\n",
        "\n",
        "# Load and preprocess images\n",
        "image_data = []\n",
        "image_ids = test_data['ID'].tolist()\n",
        "for img_id in tqdm(image_ids, desc=\"Processing Images\"):\n",
        "    img_path = f\"{working_directory}images_composition_test/{img_id}_composition.jpg\"  # Adjust the extension if needed\n",
        "    img = load_img(img_path)\n",
        "    img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "    image_data.append(img_array)\n",
        "\n",
        "X_test_images = np.array(image_data)\n",
        "\n",
        "# Run the model to get predictions\n",
        "predictions = model.predict([X_test_images, X_test_structured])\n",
        "\n",
        "# Save predictions to \"predictions.csv\"\n",
        "prediction_results = pd.DataFrame({'ID': image_ids, 'Price': predictions.flatten()})\n",
        "prediction_results.to_csv(working_directory+\"predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to 'predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4axWaf52DJit",
        "outputId": "ba176f2a-1744-4835-95ca-e634ed14d450"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing Images:   0%|          | 0/107 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Images:  18%|█▊        | 19/107 [00:00<00:00, 180.97it/s]\u001b[A\n",
            "Processing Images:  36%|███▌      | 38/107 [00:00<00:00, 180.56it/s]\u001b[A\n",
            "Processing Images:  53%|█████▎    | 57/107 [00:00<00:00, 183.46it/s]\u001b[A\n",
            "Processing Images:  71%|███████   | 76/107 [00:00<00:00, 161.32it/s]\u001b[A\n",
            "Processing Images: 100%|██████████| 107/107 [00:00<00:00, 167.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 17s/step\n",
            "Predictions saved to 'predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting prediction in USD:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the predictions data\n",
        "predictions = pd.read_csv(working_directory+\"predictions.csv\")\n",
        "\n",
        "# Apply the transformation to the 'Price' column\n",
        "predictions['Price'] = np.exp(predictions['Price'] + 9)\n",
        "\n",
        "# Load the submission template\n",
        "submission = pd.read_csv(working_directory+\"submission_template.csv\")\n",
        "\n",
        "# Update the 'Price' in submission with the calculated values from predictions based on 'ID'\n",
        "submission = submission.merge(predictions[['ID', 'Price']], on='ID', how='left')\n",
        "\n",
        "# Save the updated submission template\n",
        "submission.to_csv(working_directory+\"submission_template.csv\", index=False)"
      ],
      "metadata": {
        "id": "m23p1cVJG6mM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = working_directory+\"submission_template.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Keep only the \"ID\" and \"Price\" columns\n",
        "df = df[['ID', 'Price']]\n",
        "\n",
        "# Save the modified DataFrame back to the CSV file\n",
        "df.to_csv(file_path, index=False)\n"
      ],
      "metadata": {
        "id": "OS1R-b9HqHNN"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}